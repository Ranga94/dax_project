{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Analyst Opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymongo\n",
    "import re\n",
    "from re import sub\n",
    "from decimal import Decimal\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import scipy\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_constituents = ['Allianz', 'Adidas', 'BASF', 'Bayer', 'Beiersdorf','BMW', 'Commerzbank', 'Continental', 'Daimler','Deutsche_Bank', 'Deutsche_Boerse', 'Deutsche_Post','Deutsche_Telekom', 'EON', 'Fresenius', 'HeidelbergCement', 'Infineon','Linde','Lufthansa', 'Merck', 'RWE', 'Siemens', 'Thyssenkrupp','Vonovia','Fresenius_Medical_Care','Munich_RE','ProSiebenSat1_Media','Volkswagen_vz']\n",
    "constituents_list=['Adidas', 'Commerzbank', 'BMW', 'Deutsche_Bank', 'EON']\n",
    "all_constituents_dict_bi = {'Allianz':'Allianz', 'Adidas':'Adidas', 'BASF':'BASF', 'Bayer':'Bayer', 'Beiersdorf':'Beiersdorf',\n",
    "                    'BMW':'BMW', 'Commerzbank':'Commerzbank', 'Continental':'Continental', 'Daimler':'Daimler',\n",
    "                    'Deutsche Bank':'Deutsche_Bank', 'Deutsche Börse':'Deutsche_Boerse', 'Deutsche Post':'Deutsche_Post',\n",
    "                    'Deutsche Telekom':'Deutsche_Telekom', 'EON':'EON', 'Fresenius Medical Care':'Fresenius_Medical_Care',\n",
    "                    'Fresenius':'Fresenius', 'HeidelbergCement':'HeidelbergCement', 'Infineon':'Infineon',\n",
    "                    'Linde':'Linde','Lufthansa':'Lufthansa', 'Merck':'Merck', 'Münchener Rückversicherungs-Gesellschaft': 'Munich_Re',\n",
    "                    'ProSiebenSat1 Media':'ProSiebenSat1_Media', 'RWE':'RWE', 'Siemens':'Siemens', 'Thyssenkrupp':'thyssenkrupp',\n",
    "                    'Volkswagen (VW) vz':'Volkswagen_vz','Vonovia':'Vonovia'}\n",
    "#,'Vonovia':'Vonovia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Insider Analyst Data - Major resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write a function that extract analyst data for all stocks\n",
    "def analyst_businessinsider(constituents_dict): \n",
    "    analyst_opinion_table = pd.DataFrame()\n",
    "        \n",
    "    for constituent in constituents_dict:\n",
    "        \n",
    "        if constituent == 'SAP':\n",
    "            url = 'http://www.reuters.com/finance/stocks/analyst/SAP'\n",
    "            soup = BeautifulSoup(r,'lxml')\n",
    "            tables = soup.find_all('div', class_='moduleBody')\n",
    "            analyst_recommendation = tables[2].find_all('td',class_='data')\n",
    "            rating = float(analyst_recommendation[-4].text)     \n",
    "        #print constituent\n",
    "        url = 'http://markets.businessinsider.com/analyst/'+constituents_dict[constituent]\n",
    "        #url = 'http://markets.businessinsider.com/stock/'+constituents_dict[constituent]+'/analysts-opinions'\n",
    "        r = urllib.urlopen(url).read()\n",
    "        soup = BeautifulSoup(r,'lxml')\n",
    "        rating_extract = soup.find_all(\"div\",class_=\"rating\")\n",
    "        rating = float(rating_extract[0].text)\n",
    "                             \n",
    "        #Obtain the data inside the table as a resultset (list) and extract the text. \n",
    "        opinions = soup.find_all(\"td\",class_=[\"bar buy\",'bar overweight',\"bar hold\",\"bar underweight\",\"bar sell\"])\n",
    "        opinions_data = [int(x.text) for x in opinions]\n",
    "        buy_count=opinions_data[0]+opinions_data[1]\n",
    "        hold_count=opinions_data[2]\n",
    "        sell_count=opinions_data[3]+opinions_data[4]\n",
    "        total = buy_count+hold_count+ sell_count\n",
    "    \n",
    "        #Find analyst target for stock prices\n",
    "        letters = soup.find_all(\"table\",class_='table table-small no-margin-bottom')\n",
    "        letters2 = letters[0].find_all(\"td\")\n",
    "        target_list = [str(x.text.strip()) for x in letters2]\n",
    "\n",
    "        #Extract the prices. \n",
    "        median_target = round(float(target_list[5].replace(\"EUR\",\"\")),2)\n",
    "        highest_target = round(float(target_list[7].replace(\"EUR\",\"\")),2)\n",
    "        lowest_target = round(float(target_list[9].replace(\"EUR\",\"\")),2)\n",
    "\n",
    "                             \n",
    "        #Allocate a status according to the rating\n",
    "        if rating <= 2:\n",
    "            rating_result='Strong buy'\n",
    "        elif rating <= 2.8:\n",
    "            rating_result = 'Moderate buy'\n",
    "        elif rating <= 3.2:\n",
    "            rating_result = 'Hold'\n",
    "        elif rating <=4:\n",
    "            rating_result = 'Moderate sell'\n",
    "        else: \n",
    "            rating_result = 'Strong sell'\n",
    "        \n",
    "        analyst_opinion_table = analyst_opinion_table.append(pd.DataFrame({'Constituent':constituent,'Analyst rating': rating, 'Analyst recommendation': rating_result,'Buy':buy_count,'Hold':hold_count,'Sell':sell_count,'% Buy':round(buy_count*1.0/total,3),'% Hold':round(hold_count*1.0/total,3),'% Sell':round(sell_count*1.0/total,3),'Median target price':median_target, 'Highest target price':highest_target,'Lowest target price':lowest_target,'Date':datetime.date.today(),'Table':'Analyst opinions'},index=[0],),ignore_index=True)\n",
    "    columnsTitles = ['Constituent','Analyst rating','Analyst recommendation', 'Buy','Hold','Sell','% Buy','% Hold','% Sell','Median target price','Highest target price','Lowest target price','Table','Date']\n",
    "    analyst_opinion_table =analyst_opinion_table.reindex(columns=columnsTitles)\n",
    "    return analyst_opinion_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping from FT and Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Collect rating for SAP in case Business Insider doesn't work. Use FT and Reuters   \n",
    "#url = 'https://markets.ft.com/data/equities/tearsheet/forecasts?s=DBKX.N:GER'\n",
    "#r = urllib.urlopen(url).read()\n",
    "#soup = BeautifulSoup(r,'lxml')\n",
    "#letters = soup.find_all('table' ,class_='mod-ui-table mod-ui-table--colored')\n",
    "#numbers = re.findall((r\"\\d+\", letters[0].text))\n",
    "#opinions_data= [int(x) for x in numbers]\n",
    "                             \n",
    "#Find the highest, median and lowest targets\n",
    "#letters = soup.find_all('table',class_='mod-ui-table mod-ui-table--colored mod-tearsheet-forecast__table--visible')\n",
    "#rows = letters[0].findAll('tr')\n",
    "#data = [[td.findChildren(text=True) for td in tr.findAll(\"td\")] for tr in rows]\n",
    "#highest_target = float(data[0][2][0])\n",
    "#median_target = float(data[1][2][0])\n",
    "#lowest_target = float(data[2][2][0])\n",
    "        \n",
    "#Collect the analyst rating separately\n",
    "#r = urllib.urlopen('http://www.reuters.com/finance/stocks/analyst/DBKGn.DE').read()\n",
    "#soup = BeautifulSoup(r,'lxml')\n",
    "#tables = soup.find_all('div', class_='moduleBody')\n",
    "#analyst_recommendation = tables[2].find_all('td',class_='data')\n",
    "#rating = float(analyst_recommendation[-4].text)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wall Street Journal - Five selected constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyst_wallstreet():\n",
    "    analyst_opinions_table = pd.DataFrame()\n",
    "    constituent_dict = {'Adidas':'ADS','Commerzbank':'CBK','Deutsche Bank':'DBK', 'EON':'EOAN', 'BMW':'BMW'}\n",
    "    for constituent in constituent_dict:\n",
    "        url = 'http://quotes.wsj.com/DE/XFRA/'+constituent_dict[constituent]+'/research-ratings'\n",
    "        r = urllib.urlopen(url).read()\n",
    "        soup = BeautifulSoup(r,'lxml')\n",
    "    \n",
    "        ## Find analyst opinions\n",
    "        letters = soup.find_all('div' ,class_='cr_analystRatings cr_data module')\n",
    "        numbers = letters[0].find_all('span',class_='data_data')\n",
    "        num_array = [float(x.text) for x in numbers]\n",
    "        opinions_data = [num_array[i*3+2] for i in range(5)]\n",
    "        buy_count=opinions_data[0]+opinions_data[1]\n",
    "        hold_count=opinions_data[2]\n",
    "        sell_count=opinions_data[3]+opinions_data[4]\n",
    "        total = buy_count+hold_count+ sell_count\n",
    "\n",
    "        ## Find target prices\n",
    "        letters2 = soup.find_all('div' ,class_='cr_data rr_stockprice module')\n",
    "        data = letters2[0].find_all('span',class_='data_data')\n",
    "        target_prices = [float(x.text[1:]) for x in data]\n",
    "        highest_target = target_prices[0]\n",
    "        lowest_target = target_prices[2]\n",
    "        median_target = target_prices[1]\n",
    "        analyst_opinions_table = analyst_opinions_table.append(pd.DataFrame({'Constituent':constituent,'Buy':buy_count,'Hold':hold_count,'Sell':sell_count,'% Buy':round(buy_count*1.0/total,3),'% Hold':round(hold_count*1.0/total,3),'% Sell':round(sell_count*1.0/total,3),'Median target price':median_target, 'Highest target price':highest_target,'Lowest target price':lowest_target,'Date':datetime.date.today(),'Table':'Analyst opinions'},index=[0],),ignore_index=True)\n",
    "    columnsTitles = ['Constituent', 'Buy','Hold','Sell','% Buy','% Hold','% Sell','Median target price','Highest target price','Lowest target price','Table','Date']\n",
    "    analyst_opinions_table =analyst_opinions_table.reindex(columns=columnsTitles)\n",
    "    return analyst_opinions_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Wall Street and Business Insider for 5 constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combined_analyst(ws_analyst_table, bi_analyst_table):\n",
    "    constituent_list = ['Adidas','Commerzbank','Deutsche Bank', 'EON', 'BMW']\n",
    "    combined_analyst_table = pd.DataFrame()\n",
    "    for constituent in constituent_list:\n",
    "        ##Add the number of buy, sell and hold\n",
    "        #print ws_analyst_table['Buy'].loc[ws_analyst_table['Constituent']==constituent]\n",
    "        #print bi_analyst_table['Buy'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        rating = bi_analyst_table['Analyst rating'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        recommendation = bi_analyst_table['Analyst recommendation'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        buy= ws_analyst_table['Buy'].loc[ws_analyst_table['Constituent']==constituent].values[0]+bi_analyst_table['Buy'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        sell=ws_analyst_table['Sell'].loc[ws_analyst_table['Constituent']==constituent].values[0]+bi_analyst_table['Sell'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        hold=ws_analyst_table['Hold'].loc[ws_analyst_table['Constituent']==constituent].values[0]+bi_analyst_table['Hold'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        total = buy+sell+hold\n",
    "        \n",
    "        #Find the average of highest, median and lowest target prices\n",
    "        mean_highest_target = (ws_analyst_table['Highest target price'].loc[ws_analyst_table['Constituent']==constituent].values[0]+bi_analyst_table['Highest target price'].loc[bi_analyst_table['Constituent']==constituent].values[0])/2.0\n",
    "        mean_median_target = (ws_analyst_table['Median target price'].loc[ws_analyst_table['Constituent']==constituent].values[0]+bi_analyst_table['Median target price'].loc[bi_analyst_table['Constituent']==constituent].values[0])/2.0\n",
    "        mean_lowest_target = (ws_analyst_table['Lowest target price'].loc[ws_analyst_table['Constituent']==constituent].values[0]+bi_analyst_table['Lowest target price'].loc[bi_analyst_table['Constituent']==constituent].values[0])/2.0\n",
    "        \n",
    "        \n",
    "        rating = bi_analyst_table['Analyst rating'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        recommendation = bi_analyst_table['Analyst recommendation'].loc[bi_analyst_table['Constituent']==constituent].values[0]\n",
    "        combined_analyst_table = combined_analyst_table.append(pd.DataFrame({'Constituent':constituent, 'Analyst rating': rating,'Analyst recommendation': recommendation,'Buy':buy,'Hold':hold,'Sell':sell,'% Buy':round(buy*1.0/total,3),'% Hold':round(hold/total,3),'% Sell':round(sell/total,3),'Median target price':round(mean_median_target,2), 'Highest target price':round(mean_highest_target,2),'Lowest target price':round(mean_lowest_target,2),'Date': str(datetime.date.today()),'Table':'Analyst opinions'},index=[0]),ignore_index=True)\n",
    "    columnsTitles = ['Constituent', 'Buy','Hold','Sell','% Buy','% Hold','% Sell','Analyst rating','Analyst recommendation','Median target price','Highest target price','Lowest target price','Table','Date']\n",
    "    combined_analyst_table = combined_analyst_table.reindex(columns=columnsTitles)\n",
    "    return combined_analyst_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining the analyst opinions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#analyst_opinions_selected.to_csv('analyst_opinions_selected.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Running the scraping for all the websites and combine to produce combined analyst table for five selected constituents\n",
    "bi_analyst_table = analyst_businessinsider(all_constituents_dict_bi)\n",
    "ws_analyst_table = analyst_wallstreet()\n",
    "combined_analyst_table = combined_analyst(ws_analyst_table, bi_analyst_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "combined_analyst_json = json.loads(combined_analyst_table.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading results onto MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x116be9960>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_new = MongoClient('mongodb://igenie_readwrite:igenie@35.189.101.142:27017/dax_gcp')\n",
    "db = client_new.dax_gcp\n",
    "#db['analyst_opinions'].drop()\n",
    "#db['analyst_opinions'].insert_many(combined_analyst_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Or update the existing database with new values. \n",
    "def update_analyst(combined_analyst_json):\n",
    "    constituent_list = ['Adidas','Commerzbank','Deutsche Bank', 'EON', 'BMW']\n",
    "    i=0\n",
    "    for constituent in constituent_list:\n",
    "        \n",
    "        db['analyst_opinions'].update_one({\"constituent\":constituent}, {\"$set\":combined_analyst_json[i]})\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_analyst(combined_analyst_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if data has been udpated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  1,  0,  1,  1,  0,  0,  0,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  0,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1, -1,  0,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  0,\n",
       "        0, -1,  0,  0,  0,  0,  0,  1, -1,  1,  0, -1, -1,  1,  0,  0,  0,\n",
       "        1,  1,  0,  1,  1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = list(db['news'].find())\n",
    "#data=  pd.DataFrame(list(data))\n",
    "#data['News Sentiment?'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Buy</th>\n",
       "      <th>% Hold</th>\n",
       "      <th>% Sell</th>\n",
       "      <th>Analyst rating</th>\n",
       "      <th>Analyst recommendation</th>\n",
       "      <th>Buy</th>\n",
       "      <th>Constituent</th>\n",
       "      <th>Date</th>\n",
       "      <th>Highest target price</th>\n",
       "      <th>Hold</th>\n",
       "      <th>Lowest target price</th>\n",
       "      <th>Median target price</th>\n",
       "      <th>Sell</th>\n",
       "      <th>Table</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Moderate sell</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>21.95</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.05</td>\n",
       "      <td>16.02</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Analyst opinions</td>\n",
       "      <td>59ccddc26e74a17ae1570cb1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % Buy  % Hold  % Sell  Analyst rating Analyst recommendation   Buy  \\\n",
       "0  0.167   0.433     0.4             3.3          Moderate sell  10.0   \n",
       "\n",
       "     Constituent        Date  Highest target price  Hold  Lowest target price  \\\n",
       "0  Deutsche Bank  2017-09-28                 21.95  26.0                11.05   \n",
       "\n",
       "   Median target price  Sell             Table                       _id  \n",
       "0                16.02  24.0  Analyst opinions  59ccddc26e74a17ae1570cb1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = list(db['analyst_opinions'].find({'Constituent':'Deutsche Bank'}))\n",
    "#analyst_retrieved =  pd.DataFrame(list(data))\n",
    "#analyst_retrieved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the Analyst Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal stacked bar for analyst opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot horizontal barchart using data in the table, presenting only the selected constituents in constituent_list\n",
    "def barh_opinions(constituent_list,analyst_opinions_table,ht): \n",
    "    # the width of the bars,usually 0.35 for five selected constituents displayed\n",
    "    constituents_list=['Adidas', 'Commerzbank', 'BMW', 'Deutsche_Bank', 'EON']\n",
    "    analyst_opinions_table = analyst_opinions_table[analyst_opinions_table['Constituent'].isin(constituents_list)]\n",
    "    N = len(analyst_opinions_table['Constituent'])\n",
    "    buy_pct = analyst_opinions_table['% Buy']*100\n",
    "    hold_pct = analyst_opinions_table['% Hold']*100\n",
    "    sell_pct = analyst_opinions_table['% Sell']*100\n",
    "    fig = plt.clf()\n",
    "    fig,ax= plt.subplots(figsize=(8,N/1.5))\n",
    "    ind = np.arange(N)    # the x locations for the groups\n",
    "    p1 = ax.barh(ind, sell_pct,height=ht,color='r')\n",
    "    p2 = ax.barh(ind, hold_pct,height=ht, left=sell_pct,color='#ffc000')\n",
    "    p3 = ax.barh(ind, buy_pct,height=ht, left=hold_pct+sell_pct,color='g')\n",
    "    \n",
    "    i=0\n",
    "    for p in p1.patches:\n",
    "            if sell_pct.iloc[i]==0: \n",
    "                ax.annotate('', (p.get_width()/3,p.xy[1]+0.1))\n",
    "            else:\n",
    "                ax.annotate(str(sell_pct.iloc[i])+'%', (p.get_width()/6,p.xy[1]+0.1))\n",
    "            i=i+1\n",
    "    i=0\n",
    "    for p in p2.patches:\n",
    "        ax.annotate(str(hold_pct.iloc[i])+'%', (p.xy[0]+p.get_width()/3,p.xy[1]+0.1))\n",
    "        i=i+1\n",
    "    i=0\n",
    "    for p in p3.patches:\n",
    "        ax.annotate(str(buy_pct.iloc[i])+'%', (p.xy[0]+p.get_width()/3,p.xy[1]+0.1))\n",
    "        i=i+1\n",
    "    \n",
    "    \n",
    "    #plt.ylabel('Constituents')\n",
    "    plt.xlabel('Percentage of Analyst')\n",
    "    plt.title('Analyst Opinions')\n",
    "    plt.yticks(ind,analyst_opinions_table['Constituent'])\n",
    "    plt.xticks(np.arange(0,110,10))\n",
    "    # Put a legend below current axis\n",
    "    #ax.legend(loc='center left', bbox_to_anchor=(0.5, -0.05),fancybox=True, shadow=True, nrow=3)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width, box.height])\n",
    "    ax.legend((p1[0], p2[0], p3[0]), ('% Sell', '% Hold','% Buy'),loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#barh_opinions(constituents_list,analyst_opinions_table,ht=0.50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyst ratings and recommendation in vertical scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Presenting the target prices and analyst prediction in a scatter plot, only for selected constituents in the constituents_list\n",
    "def opinion_scatter(constituents_list,analyst_opinions_table):\n",
    "    colors = []\n",
    "    for constituent in constituents_list: # keys are the names of the boys\n",
    "        status = analyst_opinions_table['Analyst recommendation'].loc[analyst_opinions_table['Constituent']==constituent]\n",
    "        if status.values[0] == 'Strong buy':\n",
    "            colors.append('g')\n",
    "        elif status.values[0] == 'Moderate buy':\n",
    "            colors.append('#A9CE1D') #lime?\n",
    "        elif status.values[0] == 'Hold':\n",
    "            colors.append('#ffc000')\n",
    "        elif status.values[0] == 'Moderate sell':\n",
    "            colors.append('#FF8633')\n",
    "        else:\n",
    "            colors.append('r')\n",
    "            \n",
    "        plt.clf()\n",
    "        \n",
    "    constituents_list=['Adidas', 'Commerzbank', 'BMW', 'Deutsche_Bank', 'EON']\n",
    "    analyst_opinions_table = analyst_opinions_table[analyst_opinions_table['Constituent'].isin(constituents_list)]\n",
    "    X = analyst_opinions_table['Analyst rating']\n",
    "    fig, ax = plt.subplots(figsize=(1,8))\n",
    "    ax.scatter([1]*len(X),X, c=colors,\n",
    "           marker='s', s=100)\n",
    "\n",
    "    ax.yaxis.set_visible(True)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    #ax.get_yaxis().set_ticklabels(['what'])\n",
    "    plt.ylim(min(X)-0.4,(max(X+0.4)))\n",
    "    plt.ylabel('Rating')\n",
    "    #plt.title('Analyst recommendation')\n",
    "    plt.figtext(.5,.9,'Analyst Rating & Recommendation ', fontsize=12, ha='left')\n",
    "\n",
    "    for constituent in constituents_list: \n",
    "        recommendation = analyst_opinions_table['Analyst recommendation'].loc[analyst_opinions_table['Constituent']==constituent]\n",
    "        ax.annotate('%s, %s'%(constituent,recommendation.values[0]), xy=(1.1,analyst_opinions_table['Analyst rating'].loc[analyst_opinions_table['Constituent']==constituent]), textcoords='data')\n",
    "        #ax.annotate('%s' , xy=(1.1,analyst_opinion_table['Analyst rating'].loc[analyst_opinion_table['Constituent']==constituent]-0.1), textcoords='data')\n",
    "    #for xy in zip([1]*len(X),X):\n",
    "        #print xy[1]\n",
    "        #ax.annotate('%s' %xy[1], xy=xy, textcoords='data')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#opinion_scatter(constituents_list,analyst_opinions_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
